{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "koelectra_kakao_added.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39wkC0WAlC5U"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "XZmWHn1Lm28f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
        "from torch import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "warnings.filterwarnings(action='ignore')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "faCwViWum251"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 모델을 불러옵니다."
      ],
      "metadata": {
        "id": "KycGfSPqnDO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ElectraModel, ElectraTokenizer\n",
        "from transformers import ElectraForSequenceClassification, AdamW\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "model = ElectraForSequenceClassification.from_pretrained('monologg/koelectra-small-v2-discriminator')\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-small-v2-discriminator\")"
      ],
      "metadata": {
        "id": "w27kq8M6m23H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier.out_proj =  nn.Sequential( nn.Linear(256, 1),\n",
        "                                           nn.Sigmoid())\n",
        "\n",
        "model.load_state_dict(torch.load(f'/content/gdrive/MyDrive/A3_datasets/KoElectra/koelectra_datasets/koelectra_model5/checkpoint_{cate}.pt'))"
      ],
      "metadata": {
        "id": "auARP-YFnC_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ciGrh0i7m20L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 모두에게 동일하게 적용될 테스트셋을 생성합니다."
      ],
      "metadata": {
        "id": "mwy5KCwpn4Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadDataset(Dataset):\n",
        "    def __init__(self, df, tk):\n",
        "        self.df = df\n",
        "        self.tokenizer = tk\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx, :].values\n",
        "        # target이 없는경우 (즉, 문장만 입력된 경우)\n",
        "        if len(row) <= 1:\n",
        "            text = row[0]\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                text, \n",
        "                return_tensors='pt',\n",
        "                truncation=True,\n",
        "                max_length=50,\n",
        "                pad_to_max_length=True,\n",
        "                add_special_tokens=True\n",
        "                )\n",
        "            \n",
        "            input_ids = inputs['input_ids'][0]\n",
        "            attention_mask = inputs['attention_mask'][0]\n",
        "\n",
        "            return input_ids, attention_mask     \n",
        "            \n",
        "        # target이 있는 경우 (원래 코드)\n",
        "        else:\n",
        "            text = row[0]\n",
        "            y = row[1]\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                text, \n",
        "                return_tensors='pt',\n",
        "                truncation=True,\n",
        "                max_length=50,\n",
        "                pad_to_max_length=True,\n",
        "                add_special_tokens=True\n",
        "                )\n",
        "            \n",
        "            input_ids = inputs['input_ids'][0]\n",
        "            attention_mask = inputs['attention_mask'][0]\n",
        "\n",
        "            return input_ids, attention_mask, y"
      ],
      "metadata": {
        "id": "oatSGHv-m2xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트용 데이터를 불러옵니다.\n",
        "PATH = '/content/gdrive/MyDrive/A3_datasets/KoElectra/koelectra_datasets/'\n",
        "cate = '악플욕설'\n",
        "df = pd.read_csv(PATH + f'{cate}.csv')\n",
        "df = df[['문장', f'{cate}']]\n",
        "\n",
        "def dataSplit(dataset, y_label):\n",
        "  X_train, X_val= train_test_split(dataset, test_size = 0.2, stratify = dataset[y_label], random_state =427)\n",
        "  return X_train, X_val\n",
        "\n",
        "X_train, X_test = dataSplit(df, cate)"
      ],
      "metadata": {
        "id": "a3JmGv5um2uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = LoadDataset(X_test, tokenizer) # 이 테스트셋은 unsmile.csv로만 전이학습한 모델의 평가데이터와 동일합니다."
      ],
      "metadata": {
        "id": "7FMF_wShm2sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 추가로 전이학습할 카카오 데이터 불러오기"
      ],
      "metadata": {
        "id": "pKSxtZQ8oyp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 카카오 데이터를 불러옵니다.\n",
        "PATH = '/content/gdrive/MyDrive/A3_datasets/sudo_labeling/kakao/'\n",
        "kakao_df = pd.read_csv(PATH + f'{cate}.csv')\n",
        "kakao_df = kakao_df[['text',f'{cate}']]\n",
        "\n",
        "X_train, X_valid = dataSplit(kakao_df, cate)\n",
        "\n",
        "train_set = LoadDataset(X_train, tokenizer)\n",
        "val_set = LoadDataset(X_valid, tokenizer)"
      ],
      "metadata": {
        "id": "DJs42KZXm2pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z2tqU4Xkm2m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 카카오 데이터로 전이학습"
      ],
      "metadata": {
        "id": "YNdOxKato4RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "UNjbYZDwm2kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_cosine_schedule_with_warmup, AdamW\n",
        "\n",
        "epochs = 300 # epochs 증가\n",
        "batch_size = 64 # batch size 감소\n",
        "warmup_ratio=0.1\n",
        "t_total = len(train_set) * epochs\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, eps = 1e-8) # lr 1/10으로 변경\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size) # val loader 추가\n",
        "test_loader = DataLoader(test_set, batch_size = batch_size) # test loader 추가\n",
        "loss_f = nn.BCEWithLogitsLoss() # loss f 변경\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=1, num_training_steps=t_total)"
      ],
      "metadata": {
        "id": "GUWR_SMSm2hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/Bjarten/early-stopping-pytorch\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path=f'/content/gdrive/MyDrive/A3_datasets/KoElectra/koelectra_datasets/koelectra_kakao/checkpoint_{cate}_kakao.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "YRhJtWEdm2e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(patience = 7, verbose = True)"
      ],
      "metadata": {
        "id": "7esM8ImQm2cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "for i in tqdm(range(epochs)):\n",
        "    train_loss_list = [] # 변수 변경\n",
        "    val_loss_list = []\n",
        "    val_score_list = []\n",
        "\n",
        "    epoch_train_loss = []\n",
        "    epoch_val_loss = []\n",
        "    epoch_val_score = []\n",
        "    # train\n",
        "    model.train()\n",
        "    for input_ids_batch, attention_masks_batch, y_batch in train_loader:\n",
        "        input_ids_batch = input_ids_batch.to(device)\n",
        "        attention_masks_batch = attention_masks_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(input_ids_batch, attention_mask=attention_masks_batch).logits.reshape(-1)\n",
        "#        print(y_pred)\n",
        "        loss = loss_f(y_pred.type(torch.FloatTensor), y_batch.type(torch.FloatTensor))\n",
        "#        print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        train_loss_list.append(loss.item())\n",
        "\n",
        "    # validation loss\n",
        "    model.eval()\n",
        "    for input_ids_batch_val, attention_masks_batch_val, y_batch_val in val_loader:\n",
        "        input_ids_batch_val = input_ids_batch_val.to(device)\n",
        "        attention_masks_batch_val = attention_masks_batch_val.to(device)\n",
        "        y_batch_val = y_batch_val.to(device)\n",
        "        y_pred_val = model(input_ids_batch_val, attention_mask = attention_masks_batch_val).logits.reshape(-1)\n",
        "        loss = loss_f(y_pred_val.type(torch.FloatTensor), y_batch_val.type(torch.FloatTensor))\n",
        "        val_score = roc_auc_score(y_batch_val.tolist(), y_pred_val.tolist())\n",
        "        val_loss_list.append(loss.item())\n",
        "        val_score_list.append(val_score)\n",
        "\n",
        "    # epoch당 loss 계산 (for early stopping)\n",
        "    train_loss = np.average(train_loss_list)\n",
        "    val_loss = np.average(val_loss_list)\n",
        "    val_score = np.average(val_score_list)\n",
        "\n",
        "    epoch_train_loss.append(train_loss)\n",
        "    epoch_val_loss.append(val_loss)\n",
        "    epoch_val_score.append(val_score)\n",
        "    epoch_len = len(str(epochs))\n",
        "\n",
        "    print_msg = (f'[{i:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n",
        "                 f'train_loss: {train_loss:.5f} ' +\n",
        "                 f'valid_loss: {val_loss:.5f} ' +\n",
        "                 f'valid_score: {val_score:.5f}')\n",
        "\n",
        "    print(print_msg)\n",
        "    \n",
        "    # clear lists to track next epoch\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    val_score_list = []\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print('early stopping')\n",
        "        break\n",
        "    \n",
        "model.load_state_dict(torch.load(f'/content/gdrive/MyDrive/A3_datasets/KoElectra/koelectra_datasets/koelectra_kakao/checkpoint_{cate}_kakao.pt'))"
      ],
      "metadata": {
        "id": "u0Hqys0Qm2Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 스코어 확인하기"
      ],
      "metadata": {
        "id": "a3YQfEkqq81P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "score_list = []\n",
        "for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
        "    input_ids_batch = input_ids_batch.to(device)\n",
        "    attention_masks_batch = attention_masks_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    y_pred = model(input_ids_batch, attention_mask=attention_masks_batch).logits.reshape(-1)\n",
        "#    print(y_pred)\n",
        "    try:\n",
        "        score = roc_auc_score(y_batch.tolist(), y_pred.tolist())\n",
        "        score_list.append(score)\n",
        "    except: pass\n",
        "print('cate : ', cate)\n",
        "print(\"epoch roc_auc:\", np.mean(score_list))"
      ],
      "metadata": {
        "id": "-XLqo8Rom2Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9dQIKk4cm2UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T8ikm2g4m2Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DezOTcB3m2PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xVlo27Cgm2Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fAdjMV0Km2KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q8DK41p6m2F4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}