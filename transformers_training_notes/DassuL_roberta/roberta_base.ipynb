{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"roberta_base.ipynb","provenance":[],"authorship_tag":"ABX9TyNUM/2wQBSQfp83PYtVbpl5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"175ce19b63734b23a97d90570a75d09a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f02cf89f6a054cd48344ea7f4b1a08b6","IPY_MODEL_a663b702f9614902b0016db2b09cef9b","IPY_MODEL_8201b85813694224b449df64bf11dbfb"],"layout":"IPY_MODEL_53561d110955448296ed47dfb4e4fcf3"}},"f02cf89f6a054cd48344ea7f4b1a08b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27b3058a0e5344fb99ace84ac0aa8720","placeholder":"​","style":"IPY_MODEL_7e4b0f4f5c1e4056bc316e51e2540341","value":" 11%"}},"a663b702f9614902b0016db2b09cef9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f29b7df7e0504462a37b45eb6ce8f31c","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_372559c2db1a4c4e83e5ca56d071ed80","value":32}},"8201b85813694224b449df64bf11dbfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5929b36fe0ad4d0892485eb0f8db3334","placeholder":"​","style":"IPY_MODEL_78f3b76afd27489c97beedcedf9f7ad7","value":" 32/300 [09:28&lt;1:13:45, 16.51s/it]"}},"53561d110955448296ed47dfb4e4fcf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27b3058a0e5344fb99ace84ac0aa8720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e4b0f4f5c1e4056bc316e51e2540341":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f29b7df7e0504462a37b45eb6ce8f31c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"372559c2db1a4c4e83e5ca56d071ed80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5929b36fe0ad4d0892485eb0f8db3334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78f3b76afd27489c97beedcedf9f7ad7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4412d23e45bb4756b22bef4c745d830c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87720b62b57644a3803f5a5e3a9829de","IPY_MODEL_431484d07db140c68c1ab34e5032e22c","IPY_MODEL_95a86fc0b52241a79bd2737d7bf93d2d"],"layout":"IPY_MODEL_50ab51faf7014883bad190db48aa2059"}},"87720b62b57644a3803f5a5e3a9829de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17b513e56fe34310af56162bb38983c3","placeholder":"​","style":"IPY_MODEL_77fc25252b8643d1953adbfe49790543","value":"100%"}},"431484d07db140c68c1ab34e5032e22c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ad065f01a9a464b80499793bf79c81a","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21e96303835649f68023e34b860e0df9","value":3}},"95a86fc0b52241a79bd2737d7bf93d2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5779ea797324af1b65fb76f224653d2","placeholder":"​","style":"IPY_MODEL_d0cead24493148c6a87b0c9912126fe1","value":" 3/3 [00:01&lt;00:00,  3.16it/s]"}},"50ab51faf7014883bad190db48aa2059":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17b513e56fe34310af56162bb38983c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77fc25252b8643d1953adbfe49790543":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ad065f01a9a464b80499793bf79c81a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21e96303835649f68023e34b860e0df9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5779ea797324af1b65fb76f224653d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0cead24493148c6a87b0c9912126fe1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gcsBh1TsU-dI","executionInfo":{"status":"ok","timestamp":1650961698043,"user_tz":-540,"elapsed":19453,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}},"outputId":"0de524b9-89b4-4772-850d-10fc3acb16d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 43.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 43.7 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 35.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBmTqGihXV1O","executionInfo":{"status":"ok","timestamp":1650961726279,"user_tz":-540,"elapsed":18471,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}},"outputId":"b96cbcfa-0828-4e42-bc21-1f3a33ff1bcc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from tqdm.notebook import tqdm\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","%matplotlib inline"],"metadata":{"id":"7pA9rMPNXZDM","executionInfo":{"status":"ok","timestamp":1650961790566,"user_tz":-540,"elapsed":3380,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer\n","\n","model = AutoModel.from_pretrained(\"klue/roberta-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5Hb2iJkXAQ6","executionInfo":{"status":"ok","timestamp":1650962783678,"user_tz":-540,"elapsed":4383,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}},"outputId":"f4a0dca1-7734-4fcf-c3af-685673afbebf"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["# data"],"metadata":{"id":"oGQVH08RX9iq"}},{"cell_type":"code","source":["PATH = '/content/gdrive/MyDrive/A3_datasets/KoElectra/koelectra_datasets/'\n","cate = '개인지칭'\n","df = pd.read_csv(PATH + f'{cate}.csv')"],"metadata":{"id":"wRUOLODRXcRG","executionInfo":{"status":"ok","timestamp":1650962783678,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["df = df[['문장', f'{cate}']]"],"metadata":{"id":"_cqCfiUOXpSz","executionInfo":{"status":"ok","timestamp":1650962783678,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":118,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n","from torch import torch\n","from sklearn.model_selection import train_test_split\n","\n","def dataSplit(dataset, y_label):\n","  X_train, X_val= train_test_split(dataset, test_size = 0.2, stratify = dataset[y_label], random_state =427)\n","  return X_train, X_val"],"metadata":{"id":"ryww9LnfX60x","executionInfo":{"status":"ok","timestamp":1650962783679,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = dataSplit(df, cate)\n","\n","# validation 추가\n","X_train, X_val = dataSplit(X_train, cate)"],"metadata":{"id":"OQMQKfVzX8Y8","executionInfo":{"status":"ok","timestamp":1650962784016,"user_tz":-540,"elapsed":340,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["class LoadDataset(Dataset):\n","    def __init__(self, df, tk):\n","        self.df = df\n","        self.tokenizer = tk\n","\n","    def __len__(self):\n","        return len(self.df)\n","  \n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx, :].values\n","        # target이 없는경우 (즉, 문장만 입력된 경우)\n","        if len(row) <= 1:\n","            text = row[0]\n","\n","            inputs = self.tokenizer(\n","                text, \n","                return_tensors='pt',\n","                truncation=True,\n","                max_length=50,\n","                pad_to_max_length=True,\n","                add_special_tokens=True\n","                )\n","            \n","            input_ids = inputs['input_ids'][0]\n","            attention_mask = inputs['attention_mask'][0]\n","\n","            return input_ids, attention_mask     \n","            \n","        # target이 있는 경우 (원래 코드)\n","        else:\n","            text = row[0]\n","            y = row[1]\n","\n","            inputs = self.tokenizer(\n","                text, \n","                return_tensors='pt',\n","                truncation=True,\n","                max_length=50,\n","                pad_to_max_length=True,\n","                add_special_tokens=True\n","                )\n","            \n","            input_ids = inputs['input_ids'][0]\n","            attention_mask = inputs['attention_mask'][0]\n","\n","            return input_ids, attention_mask, y"],"metadata":{"id":"caZ226t3YDP5","executionInfo":{"status":"ok","timestamp":1650962784016,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["train_set = LoadDataset(X_train, tokenizer)\n","val_set = LoadDataset(X_val, tokenizer)\n","test_set = LoadDataset(X_test, tokenizer)"],"metadata":{"id":"BdcLRDRBYEnq","executionInfo":{"status":"ok","timestamp":1650962784016,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":["# modeling"],"metadata":{"id":"fUo15FooZWYl"}},{"cell_type":"code","source":["model.pooler.dense = nn.Linear(768, 1)\n","model.pooler.activation = nn.Sigmoid()"],"metadata":{"id":"gQmptzgZg6NN","executionInfo":{"status":"ok","timestamp":1650962784016,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kJUiaybaNkk","executionInfo":{"status":"ok","timestamp":1650962784016,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}},"outputId":"94ae802d-71f6-49f9-e1c7-f6dca1628192"},"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaModel(\n","  (embeddings): RobertaEmbeddings(\n","    (word_embeddings): Embedding(32000, 768, padding_idx=1)\n","    (position_embeddings): Embedding(514, 768, padding_idx=1)\n","    (token_type_embeddings): Embedding(1, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): RobertaEncoder(\n","    (layer): ModuleList(\n","      (0): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): RobertaPooler(\n","    (dense): Linear(in_features=768, out_features=1, bias=True)\n","    (activation): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["from transformers import get_cosine_schedule_with_warmup, AdamW\n","\n","epochs = 300 # epochs 증가\n","batch_size = 64 # batch size 감소\n","warmup_ratio=0.1\n","t_total = len(train_set) * epochs\n","optimizer = AdamW(model.parameters(), lr=1e-5, eps = 1e-8) # lr 1/10으로 변경\n","train_loader = DataLoader(train_set, batch_size=batch_size)\n","val_loader = DataLoader(val_set, batch_size=batch_size) # val loader 추가\n","test_loader = DataLoader(test_set, batch_size = batch_size) # test loader 추가\n","loss_f = nn.BCEWithLogitsLoss() # loss f 변경\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=1, num_training_steps=t_total)"],"metadata":{"id":"cDl3LsGraTbX","executionInfo":{"status":"ok","timestamp":1650962784017,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":125,"outputs":[]},{"cell_type":"code","source":["# https://github.com/Bjarten/early-stopping-pytorch\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0, path=f'/content/gdrive/MyDrive/A3_datasets/roberta/checkpoint_{cate}.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): validation loss가 개선된 후 기다리는 기간\n","                            Default: 7\n","            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n","                            Default: False\n","            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n","                            Default: 0\n","            path (str): checkpoint저장 경로\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"metadata":{"id":"IDDkRZxWaY4Z","executionInfo":{"status":"ok","timestamp":1650962744818,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["early_stopping = EarlyStopping(patience = 7, verbose = True)"],"metadata":{"id":"0gDf2PR4bGY_","executionInfo":{"status":"ok","timestamp":1650962744819,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","\n","for i in tqdm(range(epochs)):\n","    train_loss_list = [] # 변수 변경\n","    val_loss_list = []\n","    val_score_list = []\n","\n","    epoch_train_loss = []\n","    epoch_val_loss = []\n","    epoch_val_score = []\n","    # train\n","    model.train()\n","    for input_ids_batch, attention_masks_batch, y_batch in train_loader:\n","        input_ids_batch = input_ids_batch.to(device)\n","        attention_masks_batch = attention_masks_batch.to(device)\n","        y_batch = y_batch.to(device)\n","        optimizer.zero_grad()\n","        y_pred = model(input_ids_batch, attention_mask=attention_masks_batch).pooler_output.reshape(-1)\n","#        print(y_pred)\n","        loss = loss_f(y_pred.type(torch.FloatTensor), y_batch.type(torch.FloatTensor))\n","#        print(loss)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        train_loss_list.append(loss.item())\n","\n","    # validation loss\n","    model.eval()\n","    for input_ids_batch_val, attention_masks_batch_val, y_batch_val in val_loader:\n","        input_ids_batch_val = input_ids_batch_val.to(device)\n","        attention_masks_batch_val = attention_masks_batch_val.to(device)\n","        y_batch_val = y_batch_val.to(device)\n","        y_pred_val = model(input_ids_batch_val, attention_mask = attention_masks_batch_val).pooler_output.reshape(-1)\n","        loss = loss_f(y_pred_val.type(torch.FloatTensor), y_batch_val.type(torch.FloatTensor))\n","        val_score = roc_auc_score(y_batch_val.tolist(), y_pred_val.tolist())\n","        val_loss_list.append(loss.item())\n","        val_score_list.append(val_score)\n","\n","    # epoch당 loss 계산 (for early stopping)\n","    train_loss = np.average(train_loss_list)\n","    val_loss = np.average(val_loss_list)\n","    val_score = np.average(val_score_list)\n","\n","    epoch_train_loss.append(train_loss)\n","    epoch_val_loss.append(val_loss)\n","    epoch_val_score.append(val_score)\n","    epoch_len = len(str(epochs))\n","\n","    print_msg = (f'[{i:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n","                 f'train_loss: {train_loss:.5f} ' +\n","                 f'valid_loss: {val_loss:.5f} ' +\n","                 f'valid_score: {val_score:.5f}')\n","\n","    print(print_msg)\n","    \n","    # clear lists to track next epoch\n","    train_loss_list = []\n","    val_loss_list = []\n","    val_score_list = []\n","    early_stopping(val_loss, model)\n","    if early_stopping.early_stop:\n","        print('early stopping')\n","        break\n","    \n","model.load_state_dict(torch.load(f'/content/gdrive/MyDrive/A3_datasets/roberta/checkpoint_{cate}.pt'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["175ce19b63734b23a97d90570a75d09a","f02cf89f6a054cd48344ea7f4b1a08b6","a663b702f9614902b0016db2b09cef9b","8201b85813694224b449df64bf11dbfb","53561d110955448296ed47dfb4e4fcf3","27b3058a0e5344fb99ace84ac0aa8720","7e4b0f4f5c1e4056bc316e51e2540341","f29b7df7e0504462a37b45eb6ce8f31c","372559c2db1a4c4e83e5ca56d071ed80","5929b36fe0ad4d0892485eb0f8db3334","78f3b76afd27489c97beedcedf9f7ad7"]},"id":"dZFE7VBYbHnl","executionInfo":{"status":"ok","timestamp":1650886929295,"user_tz":-540,"elapsed":569038,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}},"outputId":"dd2eb81a-bece-48c2-fdab-8b39ec57bdb3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"175ce19b63734b23a97d90570a75d09a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[  0/300] train_loss: 0.71245 valid_loss: 0.69512 valid_score: 0.58061\n","Validation loss decreased (inf --> 0.695116).  Saving model ...\n","[  1/300] train_loss: 0.69444 valid_loss: 0.69316 valid_score: 0.67540\n","Validation loss decreased (0.695116 --> 0.693163).  Saving model ...\n","[  2/300] train_loss: 0.69313 valid_loss: 0.69276 valid_score: 0.72503\n","Validation loss decreased (0.693163 --> 0.692756).  Saving model ...\n","[  3/300] train_loss: 0.69210 valid_loss: 0.69083 valid_score: 0.82141\n","Validation loss decreased (0.692756 --> 0.690829).  Saving model ...\n","[  4/300] train_loss: 0.67392 valid_loss: 0.62277 valid_score: 0.90716\n","Validation loss decreased (0.690829 --> 0.622766).  Saving model ...\n","[  5/300] train_loss: 0.59025 valid_loss: 0.54126 valid_score: 0.97383\n","Validation loss decreased (0.622766 --> 0.541256).  Saving model ...\n","[  6/300] train_loss: 0.53922 valid_loss: 0.53552 valid_score: 0.97671\n","Validation loss decreased (0.541256 --> 0.535523).  Saving model ...\n","[  7/300] train_loss: 0.52764 valid_loss: 0.53260 valid_score: 0.97940\n","Validation loss decreased (0.535523 --> 0.532598).  Saving model ...\n","[  8/300] train_loss: 0.52691 valid_loss: 0.53427 valid_score: 0.97825\n","EarlyStopping counter: 1 out of 7\n","[  9/300] train_loss: 0.52105 valid_loss: 0.52842 valid_score: 0.97199\n","Validation loss decreased (0.532598 --> 0.528419).  Saving model ...\n","[ 10/300] train_loss: 0.51981 valid_loss: 0.53377 valid_score: 0.97419\n","EarlyStopping counter: 1 out of 7\n","[ 11/300] train_loss: 0.51842 valid_loss: 0.53411 valid_score: 0.97760\n","EarlyStopping counter: 2 out of 7\n","[ 12/300] train_loss: 0.51859 valid_loss: 0.53067 valid_score: 0.97497\n","EarlyStopping counter: 3 out of 7\n","[ 13/300] train_loss: 0.51576 valid_loss: 0.53648 valid_score: 0.98095\n","EarlyStopping counter: 4 out of 7\n","[ 14/300] train_loss: 0.51631 valid_loss: 0.52752 valid_score: 0.97911\n","Validation loss decreased (0.528419 --> 0.527518).  Saving model ...\n","[ 15/300] train_loss: 0.51600 valid_loss: 0.53113 valid_score: 0.98062\n","EarlyStopping counter: 1 out of 7\n","[ 16/300] train_loss: 0.51505 valid_loss: 0.53356 valid_score: 0.98024\n","EarlyStopping counter: 2 out of 7\n","[ 17/300] train_loss: 0.51677 valid_loss: 0.53661 valid_score: 0.98306\n","EarlyStopping counter: 3 out of 7\n","[ 18/300] train_loss: 0.51480 valid_loss: 0.52509 valid_score: 0.97666\n","Validation loss decreased (0.527518 --> 0.525089).  Saving model ...\n","[ 19/300] train_loss: 0.51462 valid_loss: 0.53003 valid_score: 0.98526\n","EarlyStopping counter: 1 out of 7\n","[ 20/300] train_loss: 0.51451 valid_loss: 0.53238 valid_score: 0.98429\n","EarlyStopping counter: 2 out of 7\n","[ 21/300] train_loss: 0.51371 valid_loss: 0.52624 valid_score: 0.98526\n","EarlyStopping counter: 3 out of 7\n","[ 22/300] train_loss: 0.51366 valid_loss: 0.52631 valid_score: 0.98576\n","EarlyStopping counter: 4 out of 7\n","[ 23/300] train_loss: 0.51363 valid_loss: 0.52647 valid_score: 0.98551\n","EarlyStopping counter: 5 out of 7\n","[ 24/300] train_loss: 0.51380 valid_loss: 0.52305 valid_score: 0.97964\n","Validation loss decreased (0.525089 --> 0.523048).  Saving model ...\n","[ 25/300] train_loss: 0.51375 valid_loss: 0.52204 valid_score: 0.97807\n","Validation loss decreased (0.523048 --> 0.522042).  Saving model ...\n","[ 26/300] train_loss: 0.51349 valid_loss: 0.53038 valid_score: 0.98480\n","EarlyStopping counter: 1 out of 7\n","[ 27/300] train_loss: 0.51390 valid_loss: 0.54010 valid_score: 0.98428\n","EarlyStopping counter: 2 out of 7\n","[ 28/300] train_loss: 0.51481 valid_loss: 0.52328 valid_score: 0.97480\n","EarlyStopping counter: 3 out of 7\n","[ 29/300] train_loss: 0.51465 valid_loss: 0.53274 valid_score: 0.98306\n","EarlyStopping counter: 4 out of 7\n","[ 30/300] train_loss: 0.51480 valid_loss: 0.53006 valid_score: 0.98440\n","EarlyStopping counter: 5 out of 7\n","[ 31/300] train_loss: 0.51349 valid_loss: 0.52756 valid_score: 0.98286\n","EarlyStopping counter: 6 out of 7\n","[ 32/300] train_loss: 0.51353 valid_loss: 0.53062 valid_score: 0.98527\n","EarlyStopping counter: 7 out of 7\n","early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["model.load_state_dict(torch.load(f'/content/gdrive/MyDrive/A3_datasets/roberta/checkpoint_{cate}.pt'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cy_NMhVZ_jfn","executionInfo":{"status":"ok","timestamp":1650962794423,"user_tz":-540,"elapsed":7563,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}},"outputId":"83a7ce54-7848-4611-f5b3-71787b6adeec"},"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","model.eval()\n","valid_loader = DataLoader(val_set, batch_size=batch_size)\n","score_list = []\n","for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n","    input_ids_batch = input_ids_batch.to(device)\n","    attention_masks_batch = attention_masks_batch.to(device)\n","    y_batch = y_batch.to(device)\n","    y_pred = model(input_ids_batch, attention_mask=attention_masks_batch).pooler_output.reshape(-1)\n","#    print(y_pred)\n","    try:\n","        score = roc_auc_score(y_batch.tolist(), y_pred.tolist())\n","        score_list.append(score)\n","    except: pass\n","print('cate : ', cate)\n","print(\"epoch roc_auc:\", np.mean(score_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["4412d23e45bb4756b22bef4c745d830c","87720b62b57644a3803f5a5e3a9829de","431484d07db140c68c1ab34e5032e22c","95a86fc0b52241a79bd2737d7bf93d2d","50ab51faf7014883bad190db48aa2059","17b513e56fe34310af56162bb38983c3","77fc25252b8643d1953adbfe49790543","5ad065f01a9a464b80499793bf79c81a","21e96303835649f68023e34b860e0df9","b5779ea797324af1b65fb76f224653d2","d0cead24493148c6a87b0c9912126fe1"]},"id":"iJ28_21bmOa5","executionInfo":{"status":"ok","timestamp":1650962795328,"user_tz":-540,"elapsed":915,"user":{"displayName":"‍신지섭(학부생-빅데이터경영통계전공)","userId":"03536684182824485899"}},"outputId":"88a08b20-5abc-413c-ea4c-9de8202b9fb8"},"execution_count":127,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4412d23e45bb4756b22bef4c745d830c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["cate :  개인지칭\n","epoch roc_auc: 0.9171903365451751\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"l4vG1j5zs6xh"},"execution_count":null,"outputs":[]}]}